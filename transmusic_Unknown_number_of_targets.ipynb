{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import orth\n",
    "\n",
    "import random\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "import time\n",
    "import scipy\n",
    "import math\n",
    "import h5py\n",
    "from tqdm.auto import tqdm\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "\n",
    "myseed = 42069\n",
    "torch.backends.cudnn.deterministic = True  \n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)  \n",
    "torch.manual_seed(myseed)  \n",
    "torch.cuda.manual_seed_all(myseed)  \n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "\n",
    "print('The device used is', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# construct training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = 5   # Number of targets\n",
    "m = 8   # Number of antenna arrays\n",
    "snr = 10   # Signal to Noise Ratio\n",
    "\n",
    "mean_signal_power = 0  #Signal mean\n",
    "var_signal_power = 1  #Signal variance\n",
    "\n",
    "mean_noise = 0  #Mean noise\n",
    "var_noise = 1  #noise variance\n",
    "\n",
    "\n",
    "doa = np.pi * (np.random.rand(d) - 1/2)   \n",
    "p = np.sqrt(1) * (np.random.randn(d) + np.random.randn(d) * 1j)   \n",
    "\n",
    "array = np.linspace(0, m, m, endpoint=False) \n",
    "angles = np.array((np.linspace(- np.pi/2, np.pi/2, 360, endpoint=False),))   \n",
    "r = angles.shape[1]\n",
    "snapshots = 200\n",
    "\n",
    "\n",
    "\n",
    "#*******************************************#\n",
    "#   uniform linear array steering vector    #\n",
    "#*******************************************#\n",
    "def ULA_action_vector(theta):\n",
    "\n",
    "    array = np.linspace(0, m, m, endpoint=False) \n",
    "    return np.exp(- 1j * np.pi * array * np.sin(theta))\n",
    "\n",
    "\n",
    "\n",
    "#***********************#\n",
    "#   construct signals   #\n",
    "#***********************#\n",
    "def construct_signal(thetas,snr,snapshots):\n",
    "  \n",
    "\n",
    "    d = len(thetas)\n",
    "    \n",
    "    signal = np.sqrt(var_signal_power) * (10 ** (snr / 10)) *  (np.random.randn(d, snapshots) + 1j * np.random.randn(d, snapshots)) + mean_signal_power\n",
    "\n",
    "    A = np.array([ULA_action_vector(thetas[j]) for j in range(d)])\n",
    "\n",
    "    noise = np.sqrt(var_noise) * (np.random.randn(m, snapshots) + 1j *np.random.randn(m, snapshots)) + mean_noise\n",
    "\n",
    "    return np.dot(A.T, signal) + noise, signal\n",
    "\n",
    "\n",
    "\n",
    "#********************************#\n",
    "#   construct coherent signals   #\n",
    "#********************************#\n",
    "def construct_coherent_signal(thetas,snr,snapshots):\n",
    "\n",
    "    d = len(thetas)\n",
    "\n",
    "    signal = np.sqrt(var_signal_power) * (10 ** (snr / 10)) * (np.random.randn(1, snapshots) + 1j * np.random.randn(1, snapshots)) + mean_signal_power\n",
    "\n",
    "    signal = np.repeat(signal, d, axis=0)\n",
    "\n",
    "    A = np.array([ULA_action_vector(thetas[j]) for j in range(d)])\n",
    "    noise = np.sqrt(var_noise) * (np.random.randn(m, snapshots) + 1j *np.random.randn(m, snapshots)) + mean_noise\n",
    "\n",
    "    return np.dot(A.T, signal) + noise, signal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ********************#\n",
    "#   create dataset   #\n",
    "# ********************#\n",
    "def create_dataset(name, size,snr,snapshots ,coherent=False, save=True):\n",
    "   \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, d))\n",
    "\n",
    "    for i in tqdm(range(size)):\n",
    "        thetas = np.pi * (np.random.rand(d) - 1 / 2)  \n",
    "        if coherent:\n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else:\n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = thetas\n",
    "\n",
    "    if save:\n",
    "        hf = h5py.File(name + '.h5', 'w')\n",
    "        hf.create_dataset('X', data=X)\n",
    "        hf.create_dataset('Y', data=Thetas)\n",
    "        hf.close()\n",
    "\n",
    "    return X, Thetas\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# ********************#\n",
    "#   create dataset   #\n",
    "# ********************#\n",
    "def create_dataset(name, size,snr,snapshots ,coherent=False, save=True):\n",
    " \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, d))\n",
    "    \n",
    "    for i in tqdm(range(size)):\n",
    "        thetas = np.pi * (np.random.rand(d) - 1 / 2)  # random source directions\n",
    "        if coherent:\n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else:\n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = thetas\n",
    "\n",
    "    if save:\n",
    "        hf = h5py.File(name + '.h5', 'w')\n",
    "        hf.create_dataset('X', data=X)\n",
    "        hf.create_dataset('Y', data=Thetas)\n",
    "        hf.close()\n",
    "\n",
    "    # return X, Thetas\n",
    "\n",
    "\n",
    "\n",
    "#***************************************#\n",
    "#   create dataset with large variety   #\n",
    "#***************************************#\n",
    "def create_complete_dataset(name, size,snr, snapshots,num_sources=[d], coherent=False, save=True):\n",
    "   \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, 6))\n",
    "    for i in tqdm(range(size)):\n",
    "        num = num_sources[i % len(num_sources)]   # create equal sized sets for each num. of sources\n",
    "        thetas = np.pi * (np.random.rand(num) - 1/2)   # random source direction\n",
    "\n",
    "        if coherent: \n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else: \n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = np.pad(thetas, (0, 6 - num), 'constant', constant_values=np.pi)\n",
    "\n",
    "    if save:\n",
    "        hf = h5py.File(name + '.h5', 'w')\n",
    "        hf.create_dataset('X', data=X)\n",
    "        hf.create_dataset('Y', data=Thetas)\n",
    "        hf.close()\n",
    "\n",
    "    # return X, Thetas\n",
    "\n",
    "\n",
    "#***************************************#\n",
    "#   create dataset with large variety   #\n",
    "#***************************************#\n",
    "def create_complete_mixsnr_dataset(name,size,snapshots,num_sources=[d], coherent=False, save=True):\n",
    "   \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, 6))\n",
    "   \n",
    "    snr_list=[ 0, 5,10]\n",
    "\n",
    "    for i in tqdm(range(size)):\n",
    "        num = num_sources[i % len(num_sources)]   # create equal sized sets for each num. of sources\n",
    "        thetas = np.pi * (np.random.rand(num) - 1/2)   # random source direction\n",
    "\n",
    "        snr=snr_list[i % len(snr_list)]\n",
    "\n",
    "        if coherent: \n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else: \n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = np.pad(thetas, (0, 6 - num), 'constant', constant_values=np.pi)\n",
    "\n",
    "\n",
    "    if save:\n",
    "        hf = h5py.File(name + '.h5', 'w')\n",
    "        hf.create_dataset('X', data=X)\n",
    "        hf.create_dataset('Y', data=Thetas)\n",
    "        hf.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ********************#\n",
    "#   create dataset   #\n",
    "# ********************#\n",
    "def create_test_data(size,snr,snapshots ,coherent=False):\n",
    "   \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, d))\n",
    "    for i in tqdm(range(size)):\n",
    "        thetas = np.pi * (np.random.rand(d) - 1 / 2)  # random source directions\n",
    "        if coherent:\n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else:\n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = thetas\n",
    "\n",
    "    return X, Thetas\n",
    "\n",
    "\n",
    "\n",
    "def create_complete_test_dataset(size,snr, snapshots,num_sources=[d], coherent=False):\n",
    "   \n",
    "    X = np.zeros((size, m, snapshots)) + 1j * np.zeros((size, m, snapshots))\n",
    "    Thetas = np.zeros((size, 6))\n",
    "    for i in (range(size)):\n",
    "        num = num_sources[i % len(num_sources)]   # create equal sized sets for each num. of sources\n",
    "        thetas = np.pi * (np.random.rand(num) - 1/2)   # random source direction\n",
    "\n",
    "        if coherent: \n",
    "            X[i] = construct_coherent_signal(thetas,snr,snapshots)[0]\n",
    "        else: \n",
    "            X[i] = construct_signal(thetas,snr,snapshots)[0]\n",
    "        Thetas[i] = np.pad(thetas, (0, 6 - num), 'constant', constant_values=np.pi)\n",
    "\n",
    "\n",
    "    return X, Thetas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def permutations(predDoA):\n",
    " \n",
    "    if len(predDoA) == 0:\n",
    "        return []\n",
    "    if len(predDoA) == 1:\n",
    "        return [predDoA]\n",
    "\n",
    "    perms = []\n",
    "\n",
    "    for i in range(len(predDoA)):\n",
    "       remaining = predDoA[:i] + predDoA[i + 1:]\n",
    "\n",
    "       for perm in permutations(remaining):\n",
    "        \n",
    "           perms.append([predDoA[i]] + perm)\n",
    "\n",
    "    return perms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#*******************************#\n",
    "#   cluster small eigenvalues   #\n",
    "#*******************************#\n",
    "def cluster(evs):\n",
    " \n",
    "  \n",
    "    threshold = 1.25   # non-coherent\n",
    "    # threshold = 0.1   # coherent\n",
    "    return evs[ np.where(abs(evs) <    abs(evs[-1]) + threshold   )        ]\n",
    "\n",
    "#*********************************#\n",
    "#   the classic MUSIC algorithm   #\n",
    "#*********************************#\n",
    "def classicMUSIC(incident, array, continuum, sources=None):\n",
    "  \n",
    "    covariance = np.cov(incident)\n",
    "    eigenvalues, eigenvectors = linalg.eig(covariance)\n",
    "\n",
    "    if sources:   # number of sources known\n",
    "        d = sources\n",
    "    else:\n",
    "        n = cluster(eigenvalues).shape[0]   \n",
    "        d = array.shape[0] - n   # and get number of signal sources\n",
    "\n",
    "    En = eigenvectors[:, d:]\n",
    "\n",
    "    numSamples = continuum.shape[1]\n",
    "    spectrum = np.zeros(numSamples)\n",
    "    for axis in continuum:\n",
    "        for i in range(numSamples):\n",
    "            a = ULA_action_vector(array, axis[i])\n",
    "            spectrum[i] = 1./(a.conj().transpose() @ En @ En.conj().transpose() @ a)\n",
    "\n",
    "    DoA, _ = signal.find_peaks(spectrum)\n",
    "\n",
    "    DoA = DoA[np.argsort(spectrum[DoA])[-d:]]\n",
    "\n",
    "    return DoA, spectrum,d\n",
    "\n",
    "\n",
    "\n",
    "#*********************************#\n",
    "#   the classic MUSIC algorithm   #\n",
    "#*********************************#\n",
    "def One_bit_MUSIC(incident, array, continuum, sources=None):\n",
    "  \n",
    "    covariance = np.cov(incident)##covariance matrix\n",
    "\n",
    "    coveriance=np.pi/2*covariance;\n",
    "\n",
    "    coveriance=np.sin(coveriance)+1j*np.sin(covariance)\n",
    "\n",
    "    eigenvalues, eigenvectors = linalg.eig(covariance)\n",
    "\n",
    "\n",
    "    if sources:   # number of sources known\n",
    "        d = sources\n",
    "    else:\n",
    "        n = cluster(eigenvalues).shape[0]   # estimate multiplicity of smallest eigenvalue...\n",
    "        d = array.shape[0] - n   # and get number of signal sources\n",
    "\n",
    "    En = eigenvectors[:, d:]\n",
    "\n",
    "    numSamples = continuum.shape[1]\n",
    "    spectrum = np.zeros(numSamples)\n",
    "    for axis in continuum:\n",
    "        for i in range(numSamples):\n",
    "            a = ULA_action_vector(array, axis[i])\n",
    "            spectrum[i] = 1./(a.conj().transpose() @ En @ En.conj().transpose() @ a)\n",
    "\n",
    "    DoA, _ = signal.find_peaks(spectrum)\n",
    "\n",
    "    DoA = DoA[np.argsort(spectrum[DoA])[-d:]]\n",
    "\n",
    "    return DoA, spectrum,d\n",
    "\n",
    "\n",
    "#******************************#\n",
    "#   the Beamformer algorithm   #\n",
    "#******************************#\n",
    "def beamformer(incident, array, continuum, sources=None):\n",
    " \n",
    "    covariance = np.cov(incident)\n",
    "\n",
    "    numSamples = continuum.shape[1]\n",
    "    spectrum = np.zeros(numSamples)\n",
    "\n",
    "\n",
    "    for axis in continuum:\n",
    "        for i in range(numSamples):\n",
    "           \n",
    "            a = ULA_action_vector(array, axis[i])\n",
    "            spectrum[i] = abs(a.conj().transpose() @ covariance @ a) / linalg.norm(a)**2\n",
    "\n",
    "    DoAsMUSIC, _ = signal.find_peaks(spectrum)\n",
    "\n",
    "\n",
    "   \n",
    "    if sources: DoAsMUSIC = DoAsMUSIC[np.argsort(spectrum[DoAsMUSIC])[-sources:]]\n",
    "\n",
    "    \n",
    "    else: DoAsMUSIC = DoAsMUSIC[np.argsort(- spectrum[DoAsMUSIC])]\n",
    "\n",
    "    return DoAsMUSIC, spectrum\n",
    "\n",
    "#***********************************#\n",
    "#   mean minimal permutation rmse   #\n",
    "#***********************************#\n",
    "def mean_min_perm_rmse(predDoA, trueDoA):\n",
    "\n",
    "    num_samples = trueDoA.shape[0]\n",
    "\n",
    "    allMSE = np.zeros(num_samples)\n",
    "    for i in range(num_samples):\n",
    "\n",
    "        \n",
    "        diffs = np.zeros(np.math.factorial(trueDoA.shape[1]))\n",
    "        for j, perm in enumerate(permutations(list(predDoA[i]))):\n",
    "\n",
    "          \n",
    "            diff = ((perm - trueDoA[i]) + np.pi / 2) % np.pi - np.pi / 2\n",
    "\n",
    "          \n",
    "            diffs[j] = np.mean(diff ** 2) ** (1 / 2)\n",
    "\n",
    "      \n",
    "        allMSE[i] = np.amin(diffs)\n",
    "\n",
    "    return np.mean(allMSE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_train=200000\n",
    "num_val=20000\n",
    "num_val_snr=5000\n",
    "\n",
    "\n",
    "create_complete_dataset('train_nocoherent_snr10_200k', num_train, snr,snapshots,num_sources=[2,3,4,5], coherent=False)\n",
    "create_complete_dataset('validation_nocoherent_snr10_20k', num_val, snr,snapshots,num_sources=[2,3,4,5], coherent=False)\n",
    "create_complete_dataset('vali(100)_nocoherent_snr10_5k', num_val_snr, 10,100,num_sources=[2,3,4,5], coherent=False)\n",
    "create_complete_dataset('vali(0)2d_nocoherent_snr10_5k', num_val_snr, 10,snapshots,num_sources=[2], coherent=False)\n",
    "\n",
    "\n",
    "\n",
    "# create_complete_mixsnr_dataset('data/train_nocoherent_snrmix_200k', num_train,200,num_sources=[2,3,4,5], coherent=False)\n",
    "# create_complete_mixsnr_dataset('data/validation_nocoherent_snrmix_20k', num_val,200,num_sources=[2,3,4,5], coherent=False)\n",
    "# create_complete_dataset('data/vali(0)_nocoherent_snr0_10k', num_val_snr, 0,200,num_sources=[2,3,4,5], coherent=False)\n",
    "# create_complete_dataset('data/vali(-5)_nocoherent_snr-5_10k', num_val_snr, -5,200,num_sources=[2,3,4,5], coherent=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_augmented_MUSIC_Dataset(Dataset):\n",
    "    def __init__(self, x, y=None):   #X is the input data, y is the target data\n",
    "\n",
    "        self.data = torch.from_numpy(x).float()\n",
    "        # self.data = torch.FloatTensor(x)\n",
    "        \n",
    "\n",
    "        if y is not None:\n",
    "\n",
    "            self.label = torch.from_numpy(y).float()\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):  \n",
    "        if self.label is not None:\n",
    "            return self.data[index], self.label[index]\n",
    "        else:\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "hf_train = h5py.File('train_nocoherent_snr10_200k.h5', 'r')#read data\n",
    "hf_val = h5py.File('validation_nocoherent_snr10_20k.h5', 'r')#\n",
    "hf_val_snr = h5py.File('vali(100)_nocoherent_snr10_5k.h5', 'r')#\n",
    "hf_val_s = h5py.File('vali(0)2d_nocoherent_snr10_5k.h5', 'r')#\n",
    "\n",
    "# hf_train = h5py.File('data/train_coherent_d5_snr10_256k.h5', 'r')##read data\n",
    "# hf_val = h5py.File('data/validation_coherent_d5_snr10_25.6k.h5', 'r')#\n",
    "\n",
    "X_train = np.array(hf_train.get('X'))\n",
    "\n",
    "Y_train = np.array(hf_train.get('Y'))\n",
    "\n",
    "X_val = np.array(hf_val.get('X'))\n",
    "Y_val = np.array(hf_val.get('Y'))\n",
    "\n",
    "\n",
    "X_val_snr = np.array(hf_val_snr.get('X'))\n",
    "Y_val_snr = np.array(hf_val_snr.get('Y'))\n",
    "\n",
    "X_val_s = np.array(hf_val_s.get('X'))\n",
    "Y_val_s = np.array(hf_val_s.get('Y'))\n",
    "\n",
    "\n",
    "\n",
    "X_train=np.concatenate([X_train.real, X_train.imag], axis=1)#Splicing complex numbers into real numbers\n",
    "X_val=np.concatenate([X_val.real, X_val.imag], axis=1)#Splicing complex numbers into real numbers\n",
    "X_val_snr=np.concatenate([X_val_snr.real, X_val_snr.imag], axis=1)#Splicing complex numbers into real numbers\n",
    "X_val_s=np.concatenate([X_val_s.real, X_val_s.imag], axis=1)#Splicing complex numbers into real numbers\n",
    "\n",
    "\n",
    "\n",
    "# X_train=np.sign(X_train)#onebit bit quantization\n",
    "# X_val=np.sign(X_val)#onebit bit quantization\n",
    "\n",
    "\n",
    "X_train=np.sign(X_train)#onebit bit quantization\n",
    "X_val=np.sign(X_val)#onebit bit quantization\n",
    "X_val_snr=np.sign(X_val_snr)#onebit bit quantization\n",
    "X_val_s=np.sign(X_val_s)#onebit bit quantization\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training Set Size:\",\"Y_train\",Y_train.shape,\"X_train\",X_train.shape,X_train.dtype)\n",
    "print(\"Verification set size:\",\"Y_val\",Y_val.shape,\"X_val\",X_val.shape,X_val.dtype)\n",
    "print(\"Verification set snapshot size:\",\"Y_val_snr\",Y_val_snr.shape,\"X_val\",X_val_snr.shape,X_val_snr.dtype)\n",
    "print(\"Verify snapshot set size:\",\"Y_val_s\",Y_val_s.shape,\"X_val\",X_val_s.shape,X_val_s.dtype)\n",
    "\n",
    "\n",
    "train_set = Deep_augmented_MUSIC_Dataset(X_train,Y_train)  \n",
    "val_set = Deep_augmented_MUSIC_Dataset(X_val,Y_val)\n",
    "\n",
    "val_set_snr = Deep_augmented_MUSIC_Dataset(X_val_snr,Y_val_snr)\n",
    "val_set_s = Deep_augmented_MUSIC_Dataset(X_val_s,Y_val_s)\n",
    "\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,drop_last=True)  \n",
    "valid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False,drop_last=True)  \n",
    "\n",
    "valid_loader_snr = DataLoader(val_set_snr, batch_size=batch_size, shuffle=False,drop_last=True) \n",
    "valid_loader_s = DataLoader(val_set_s, batch_size=batch_size, shuffle=False,drop_last=True) \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  doa estimation network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.zeros([m,r])+1j*torch.zeros([m,r])\n",
    "for i in range(r):\n",
    "    a[:,i] =torch.from_numpy(ULA_action_vector(array, angles[0,i]))\n",
    "a=torch.complex(a.real.float(),a.imag.float()).to(device)\n",
    "\n",
    "\n",
    "def calculate_spectrum(En):\n",
    "\n",
    "    H1=torch.matmul(En.to(device)@ torch.conj(En.permute(0,2,1)).to(device),a).to(device)\n",
    "\n",
    "    H2=torch.mul(H1,torch.conj(a))\n",
    "\n",
    "    H3=torch.sum(H2,dim=1)\n",
    "\n",
    "    return (1.0/abs(H3)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "     \n",
    "        x = x.to(device)  + self.pe[:x.size(0)].to(device) \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# #**********************************#\n",
    "#   trans_music                    #\n",
    "#**********************************#\n",
    "\n",
    "class calculate_EVD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(calculate_EVD, self).__init__()\n",
    "      \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        size=x.shape[0]#Get batch_ Size size\n",
    "        \n",
    "        #Become pseudo Covariance matrix\n",
    "        x=torch.complex(x[ :,:8 ,:].to(device),x[ :,8: ,:].to(device))    #  [size,8,8]\n",
    "        #Eigenvector decomposition\n",
    "        xVal, xVec=torch.linalg.eig(x)\n",
    "        xVal_=abs(xVal).to(device)    #From small to large row\n",
    "        xVal_,idx=torch.sort(xVal_, dim=1) #Sort feature values to obtain an index\n",
    "        x4=xVec.to(device)\n",
    "        order_vec=torch.zeros([size,m,m]).to(device)+1j*torch.zeros([size,m,m]).to(device)\n",
    "        order_value=torch.zeros([size,m]).to(device)+1j*torch.zeros([size,m]).to(device)\n",
    "        order_vec=order_vec.to(device)\n",
    "        order_value=order_value.to(device)\n",
    "\n",
    "\n",
    "        for i in range(size):\n",
    "\n",
    "            order_vec[i,:,:]=x4[i].index_select(1,idx[i]).unsqueeze(dim=0)\n",
    "            order_value[i,:]=xVal[i].index_select(0,idx[i]).unsqueeze(dim=0)\n",
    "\n",
    "        return order_value,order_vec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RNN_music_EVD_two(nn.Module):\n",
    "\n",
    "    def __init__(self,m):\n",
    "\n",
    "        super(RNN_music_EVD_two, self).__init__()\n",
    "\n",
    "        self.m=m\n",
    "\n",
    "        self.BN=torch.nn.BatchNorm1d(2*self.m).to(device)\n",
    "        # self.LN= torch.nn.LayerNorm(normalized_shape = [16]).to(device)\n",
    "  \n",
    "        self.evd=calculate_EVD().to(device)\n",
    "\n",
    "        self.gru_layer = nn.GRU(2*self.m, 2*self.m,batch_first=True).to(device)\n",
    "\n",
    "        self.input_linear = nn.Linear(in_features=16, out_features=128).to(device) \n",
    "\n",
    "       \n",
    "        self.change_noise = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=8),\n",
    "            nn.Sigmoid()       \n",
    "                ).to(device) \n",
    "\n",
    "   \n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(in_features=360, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=6) \n",
    "                ).to(device) \n",
    "\n",
    "\n",
    "        self.output_d = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=4),\n",
    "                ).to(device)        \n",
    "\n",
    "\n",
    "    def forward(self,x,sub=True):\n",
    "\n",
    "      \n",
    "  \n",
    "\n",
    "        size=x.shape[0]\n",
    "\n",
    "        # x=x.permute(0,2,1).float().to(device)# \n",
    "        # x=self.LN(x).to(device)\n",
    "\n",
    "        # x=x.permute(0,2,1).float().to(device)# \n",
    "        x=self.BN(x).to(device)\n",
    "\n",
    "        \n",
    "        x=x.permute(0,2,1).float().to(device)# Swap the first and second dimensions into [size, 200,16]\n",
    "  \n",
    "        _,x=self.gru_layer(x) #By gating the loop unit (GRU) to [size, 16]\n",
    "      \n",
    "        x=self.input_linear(x).to(device) #The GRU output is passed to a fully connected layer, and the output 2 * 8 * 8=128 dimensions becomes [size, 128]\n",
    "\n",
    "        x=x.reshape(size,16,8).to(device) #Map it to two-dimensional pseudo covariance ˜ K 16 * 8 becomes [size, 16,8]]\n",
    "\n",
    "\n",
    "        #Eigenvector decomposition\n",
    "        xVal,xVec=self.evd(x)\n",
    "\n",
    "        xVal=xVal.detach()#Truncated gradient flow\n",
    "        xVal=torch.cat([xVal.real.float().to(device), xVal.imag.float().to(device)],dim=1)  # [size,16] \n",
    "\n",
    "\n",
    "        #Noise subspace selector\n",
    "        p=self.change_noise(xVal.to(device)) #[size,8]\n",
    "        p1=p\n",
    "        p=torch.diag_embed(p)  #Weight value   [size,8,8]\n",
    "        p=torch.complex(p,torch.zeros([size,8,8]).float().to(device)).to(device)  #[size,8,8]\n",
    "        x1=torch.matmul(p.to(device),xVec.to(device)) #Weighting eigenvectors [size,8,8]*[size,8,8]\n",
    "\n",
    "\n",
    "        #Calculate spectrum\n",
    "        x1=calculate_spectrum(x1).to(device)           \n",
    "\n",
    "        #Peak Finder\n",
    "        x1=self.output(x1.to(device)).to(device)\n",
    "\n",
    "        #Classifier for estimating d\n",
    "        x2=self.output_d(xVal)\n",
    "\n",
    "        return x1,x2,xVal\n",
    "\n",
    "\n",
    "\n",
    "#**********************************#\n",
    "#   trans_music                    #\n",
    "#**********************************#\n",
    "\n",
    "class trans_music_two(nn.Module):\n",
    "\n",
    "    def __init__(self,m):\n",
    "\n",
    "        super(trans_music_two, self).__init__()\n",
    "\n",
    "        self.m=m\n",
    "\n",
    "        self.BN=torch.nn.BatchNorm1d(16).to(device)\n",
    "        # self.LN= torch.nn.LayerNorm(normalized_shape = [16]).to(device)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(16)#Position embedding\n",
    "\n",
    "        encoder_layer=torch.nn.TransformerEncoderLayer(    #Define encoder layer\n",
    "            d_model=16, \n",
    "            nhead=8, ##The number of heads in a multi head attention model\n",
    "            dim_feedforward=1024, #Dimensions of feedforward network models\n",
    "            dropout=0, #Dropout value\n",
    "            activation=\"relu\", \n",
    "            layer_norm_eps=1e-05, \n",
    "            batch_first=True, \n",
    "            norm_first=False, \n",
    "            device=None, \n",
    "            dtype=None).to(device) \n",
    "\n",
    "\n",
    "        self.encoder=torch.nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=3, \n",
    "            norm=None).to(device) \n",
    "\n",
    "        self.input_linear = nn.Linear(in_features=16, out_features=128).to(device) \n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "\n",
    "            nn.Linear(in_features=360, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=6) \n",
    "                ).to(device) \n",
    "\n",
    "\n",
    "\n",
    "        self.output_d = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=64), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=32, out_features=4)\n",
    "                ).to(device)         \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "       \n",
    "        \n",
    "        #The input X is [size, 16200] batch_ Size=16, input dimension 16, sequence length 200\n",
    "\n",
    "\n",
    "        size=x.shape[0]#Get batch_ Size size\n",
    "\n",
    "        # x=x.permute(0,2,1).float().to(device)# Exchange dimension becomes [size, 200,16]\n",
    "\n",
    "        x=self.BN(x).to(device)#Become [size, 16200]\n",
    "        \n",
    "        # x=self.LN(x.to(device)).to(device)\n",
    "        \n",
    "\n",
    "        x=x.permute(2,0,1).float().to(device)# Exchange dimension becomes [200, size, 16]\n",
    "\n",
    "        #Position embedding\n",
    "        x=self.pos_encoder(x.to(device)).to(device)  #x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "\n",
    "        x=x.permute(1,0,2).float().to(device)# Exchange dimension becomes [size, 200,16]\n",
    "\n",
    "        x1=self.encoder(x.to(device) )    #Transformer_ Encoder network output becomes [size, 200,16]\n",
    "\n",
    "        x2=torch.mean(x1,dim=1) #Output becomes [size, 16]\n",
    "\n",
    "        x3=self.input_linear(x2).to(device) #The output is passed to a fully connected layer and becomes [size, 128]\n",
    "\n",
    "        vector=x3 #\n",
    "\n",
    "        x4=x3.reshape(size,16,8).to(device) #Change its mapping covariance to [size, 16,8]\n",
    "\n",
    "        # vector=x4  #CNN for classifier\n",
    "\n",
    "        x5=torch.complex(x4[ :,:8 ,:].to(device),x4[ :,8: ,:].to(device))    #feature vector  [size,8,8]\n",
    "\n",
    "\n",
    "        x6=calculate_spectrum(x5).to(device)  #Calculate spectrum\n",
    "\n",
    "        x7=x6.float().to(device)\n",
    "\n",
    "        x8=self.output(x7.to(device)).to(device)\n",
    "\n",
    "\n",
    "        #Classifier for estimating D\n",
    "        x9=x3  #[size,16]\n",
    "        x9=x9.detach()#Truncated gradient flow\n",
    "        x9=self.output_d(x9) \n",
    "\n",
    "    \n",
    "        return x8,x9,vector\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class trans_music_two_LN(nn.Module):\n",
    "\n",
    "    def __init__(self,m):\n",
    "\n",
    "        super(trans_music_two_LN, self).__init__()\n",
    "\n",
    "        self.m=m\n",
    "\n",
    "        # self.BN=torch.nn.BatchNorm1d(16).to(device)\n",
    "        self.LN= torch.nn.LayerNorm(normalized_shape = [16]).to(device)\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(16)#Positional embedding\n",
    "\n",
    "        encoder_layer=torch.nn.TransformerEncoderLayer(    #Define encoder layer\n",
    "            d_model=16, \n",
    "            nhead=8, ##The number of heads in the multi head attention model\n",
    "            dim_feedforward=1024, #Dimension of feedforward network model\n",
    "            dropout=0, #Dropout value\n",
    "            activation=\"relu\", \n",
    "            layer_norm_eps=1e-05, \n",
    "            batch_first=True, \n",
    "            norm_first=False, \n",
    "            device=None, \n",
    "            dtype=None).to(device) \n",
    "\n",
    "\n",
    "        self.encoder=torch.nn.TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=3, \n",
    "            norm=None).to(device) \n",
    "\n",
    "        self.input_linear = nn.Linear(in_features=16, out_features=128).to(device) \n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "\n",
    "            nn.Linear(in_features=360, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=16) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=16, out_features=6) \n",
    "                ).to(device) \n",
    "\n",
    "\n",
    "\n",
    "        self.output_d = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=64), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=32, out_features=4)\n",
    "                ).to(device)         \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #Suppose batch_ Size=16\n",
    "       \n",
    "        \n",
    "        #The entered x is [size, 16200] batch_ Size=16, enter dimension 16, sequence length 200\n",
    "\n",
    "\n",
    "        size=x.shape[0]#Get batch_ Size size\n",
    "\n",
    "        x=x.permute(0,2,1).float().to(device)# Exchange dimension becomes [size, 200,16]\n",
    "        # x=self.BN(x).to(device)#[size,16,200]\n",
    "        \n",
    "        x=self.LN(x.to(device)).to(device)\n",
    "\n",
    "\n",
    "        x=x.permute(1,0,2).float().to(device)# [200,size,16]\n",
    "\n",
    "        #Positional embedding\n",
    "        x=self.pos_encoder(x.to(device)).to(device)  #x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "\n",
    "        x=x.permute(1,0,2).float().to(device)# [size,200,16]\n",
    "\n",
    "        x1=self.encoder(x.to(device) )    #Transformer_ The encoder network output becomes [size, 200,16]\n",
    "\n",
    "        x2=torch.mean(x1,dim=1) #[size,16]\n",
    "\n",
    "        x3=self.input_linear(x2).to(device) #The output is passed to a full connection layer and becomes [size, 128]\n",
    "\n",
    "        vector=x3 #\n",
    "\n",
    "        x4=x3.reshape(size,16,8).to(device) #Change its mapping covariance to [size, 16,8]\n",
    "\n",
    "        # vector=x4  #\n",
    "\n",
    "        x5=torch.complex(x4[ :,:8 ,:].to(device),x4[ :,8: ,:].to(device))    #Eigenvector [size, 8,8]\n",
    "\n",
    "\n",
    "        x6=calculate_spectrum(x5).to(device)             #Calculate spectrum\n",
    "\n",
    "        x7=x6.float().to(device)\n",
    "\n",
    "        x8=self.output(x7.to(device)).to(device)\n",
    "\n",
    "\n",
    "        #Classifier for estimating D\n",
    "        x9=x3  #[size,16]\n",
    "        x9=x9.detach()#Truncated gradient flow\n",
    "        x9=self.output_d(x9) \n",
    "\n",
    "    \n",
    "        return x8,x9,vector\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  classifier network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class separate_est_d(nn.Module):\n",
    "    def __init__(self,name):\n",
    "        super(separate_est_d, self).__init__()\n",
    "\n",
    "        # self.BN=torch.nn.BatchNorm1d(128).to(device)\n",
    "\n",
    "        self.output_d = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=64), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=32, out_features=4)\n",
    "                ).to(device) \n",
    "        self.net_DOA=trans_music_two(m=8).to(device)      \n",
    "        self.net_DOA.load_state_dict(torch.load(name))#Model parameter loading\n",
    "    def forward(self, x):  \n",
    "        with torch.no_grad():  # disable gradient calculation\n",
    "            x8,x9,x3 = self.net_DOA(x)  #  value  [size,16]\n",
    "        \n",
    "        x10=x3  #[size,16]\n",
    "        x10=x10.detach()#Truncated gradient flow\n",
    "        # x10=self.BN(x10).to(device)\n",
    "        x10=self.output_d(x10) \n",
    "        return x10\n",
    "\n",
    "\n",
    "class separate_est_d2(nn.Module):\n",
    "    def __init__(self,name):\n",
    "        super(separate_est_d2, self).__init__()\n",
    "\n",
    "        # self.BN=torch.nn.BatchNorm1d(128).to(device)\n",
    "\n",
    "        self.output_d = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128) ,\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128), \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.Linear(in_features=128, out_features=4)\n",
    "                ).to(device) \n",
    "        self.net_DOA=RNN_music_EVD_two(m=8).to(device)      \n",
    "        self.net_DOA.load_state_dict(torch.load(name)) \n",
    "    def forward(self, x):  \n",
    "        with torch.no_grad():  # disable gradient calculation\n",
    "            x8,x9,x3 = self.net_DOA(x)  #  value  [size,16]\n",
    "       \n",
    "        x10=x3  #[size,16]\n",
    "        x10=x10.detach()\n",
    "        # x10=self.BN(x10).to(device)\n",
    "        x10=self.output_d(x10) \n",
    "        return x10\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************#\n",
    "#     #Calculate permutation\n",
    "#****************************#\n",
    "def permutations(predDoA):\n",
    " \n",
    "    if len(predDoA) == 0:\n",
    "        return []\n",
    "    if len(predDoA) == 1:\n",
    "        return [predDoA]\n",
    "\n",
    "    perms = []\n",
    "\n",
    "    for i in range(len(predDoA)):\n",
    "       remaining = predDoA[:i] + predDoA[i + 1:]\n",
    "\n",
    "       for perm in permutations(remaining):\n",
    "        \n",
    "           perms.append([predDoA[i]] + perm)\n",
    "\n",
    "    return perms\n",
    "\n",
    "\n",
    "a2=[[1,0],[0,1]]\n",
    "a2=permutations(a2)\n",
    "b2=np.array(a2)\n",
    "perm2=b2.reshape(np.math.factorial(2)*2,2)\n",
    "perm2=perm2.swapaxes(0,1)\n",
    "print(perm2.shape)\n",
    "perm2=torch.from_numpy(perm2).float().to(device)  \n",
    "\n",
    "\n",
    "\n",
    "a3=[[1,0,0],[0,1,0,],[0,0,1]]\n",
    "a3=permutations(a3);\n",
    "b3=np.array(a3)\n",
    "perm3=b3.reshape(np.math.factorial(3)*3,3)\n",
    "perm3=perm3.swapaxes(0,1)\n",
    "print(perm3.shape)\n",
    "perm3=torch.from_numpy(perm3).float().to(device)   \n",
    "\n",
    "\n",
    "a4=[[1,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]]\n",
    "a4=permutations(a4)\n",
    "b4=np.array(a4)\n",
    "perm4=b4.reshape(np.math.factorial(4)*4,4)\n",
    "perm4=perm4.swapaxes(0,1) \n",
    "print(perm4.shape)\n",
    "perm4=torch.from_numpy(perm4).float().to(device)   \n",
    "\n",
    "\n",
    "\n",
    "a5=[[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1]]\n",
    "a5=permutations(a5)\n",
    "b5=np.array(a5)\n",
    "perm5=b5.reshape(np.math.factorial(5)*5,5)\n",
    "perm5=perm5.swapaxes(0,1)\n",
    "print(perm5.shape)\n",
    "perm5=torch.from_numpy(perm5).float().to(device) \n",
    "\n",
    "\n",
    "\n",
    "def perm_rmse(predDoA, trueDoA):\n",
    "\n",
    "    size=trueDoA.shape[0]\n",
    "    num_sources = trueDoA.shape[1]\n",
    "\n",
    "    allPerms=torch.zeros(size,np.math.factorial(num_sources)*num_sources,requires_grad=True);\n",
    "\n",
    "    if num_sources==2:\n",
    "        allPerms=torch.matmul(trueDoA.to(device) ,perm2.to(device) ).to(device)  #  [size,2]  [2,4]   =[size,4]\n",
    "        allPerms=allPerms.reshape(size,2,2).to(device)      # size  2   2\n",
    "\n",
    "    elif num_sources==3:\n",
    "        allPerms=torch.matmul(trueDoA.to(device) ,perm3.to(device) ).to(device)  #  [size,3]  [3,18]   =[size,18]\n",
    "        allPerms=allPerms.reshape(size,6,3).to(device)      # size  6   3\n",
    "\n",
    "    elif num_sources==4:\n",
    "        allPerms=torch.matmul(trueDoA.to(device) ,perm4.to(device) ).to(device)  #  [size,4]  [4,96]   =[size,96]\n",
    "        allPerms=allPerms.reshape(size,24,4).to(device)      # size  24   4\n",
    "\n",
    "    elif num_sources==5:\n",
    "        allPerms=torch.matmul(trueDoA.to(device) ,perm5.to(device) ).to(device)  #  [size,5]  [5,600]   =[size,600]\n",
    "        allPerms=allPerms.reshape(size,120,5).to(device)      # size  120   5\n",
    "\n",
    "    predDoA=predDoA.unsqueeze(1).to(device) \n",
    "   \n",
    "    diff=torch.fmod( allPerms-predDoA+np.pi / 2 , np.pi ) - np.pi / 2\n",
    "\n",
    "    diff2,ind=torch.min(torch.mean(diff**2,dim=2)**(1/2),dim=1)\n",
    "\n",
    "    return  torch.mean(diff2)\n",
    "\n",
    "\n",
    "# def perm_rmse(predDoA, trueDoA):\n",
    "\n",
    "\n",
    "#     size=trueDoA.shape[0]#\n",
    "#     num_sources = trueDoA.shape[1]\n",
    "\n",
    "#     allPerms = np.zeros((size, np.math.factorial(num_sources), num_sources))# 1 120   5\n",
    "\n",
    "#     for i in range(size):\n",
    "\n",
    "#         allPerms[i] = permutations(list(trueDoA[i].cpu().numpy()))\n",
    "\n",
    "#     allPerms=torch.from_numpy(allPerms).to(device)\n",
    "\n",
    "#     predDoA=predDoA.unsqueeze(1)\n",
    "   \n",
    "#     diff=torch.fmod( allPerms-predDoA+np.pi / 2 , np.pi ) - np.pi / 2\n",
    "\n",
    "#     diff2,ind=torch.min(torch.mean(diff**2,dim=2)**(1/2),dim=1)\n",
    "\n",
    "#     return  torch.mean(diff2)\n",
    "\n",
    "\n",
    "#***************#\n",
    "#   mean rmse   #\n",
    "#***************#\n",
    "def loss_doa(predDoA,trueDoA):\n",
    "\n",
    "    num_true = torch.argmax(trueDoA, dim=1)\n",
    "\n",
    "    diff = torch.zeros(1).to(device)  \n",
    "\n",
    "    for i, elem in enumerate(num_true):\n",
    "\n",
    "        diff=diff+perm_rmse(predDoA[i, :elem].unsqueeze(dim=0),trueDoA[i, :elem].unsqueeze(dim=0))\n",
    "\n",
    "    diff= diff/len(num_true)  \n",
    "        \n",
    "    return diff\n",
    "\n",
    "\n",
    "\n",
    "def  loss_d(predp,trueDoA):\n",
    "\n",
    "    num_true = torch.argmax(trueDoA, dim=1)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    dd = torch.zeros(trueDoA.shape[0],4).to(device)#{size,4}\n",
    "\n",
    "    for i in range(trueDoA.shape[0]):\n",
    "       dd[i][num_true[i]-2]=1;\n",
    "\n",
    "    return  criterion(predp,dd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def  loss_d_by_one(predp,trueDoA):\n",
    "\n",
    "    size=trueDoA.shape[0]\n",
    "\n",
    "    num_true = torch.argmax(trueDoA, dim=1)\n",
    "\n",
    "    num_true=num_true.reshape(size,1)\n",
    "\n",
    "    diff=abs(predp-num_true)\n",
    "\n",
    "    return  torch.mean(diff)\n",
    "\n",
    "\n",
    "\n",
    "def loss_doa_test(predDoA,trueDoA,num_true_t,num_true_p):\n",
    "\n",
    "    diff = torch.zeros(1).to(device)  \n",
    "\n",
    "    for i, elem in enumerate(num_true_t):\n",
    "\n",
    "        if num_true_p[i]==num_true_t[i]:\n",
    "\n",
    "            diff=diff+perm_rmse(predDoA[i, :elem].unsqueeze(dim=0),trueDoA[i, :elem].unsqueeze(dim=0))\n",
    "\n",
    "        elif num_true_p[i]>num_true_t[i]:\n",
    "\n",
    "            diff=diff+perm_rmse(predDoA[i, :elem].unsqueeze(dim=0),trueDoA[i, :elem].unsqueeze(dim=0))\n",
    "\n",
    "        elif num_true_p[i]<num_true_t[i]:\n",
    "\n",
    "            predDoA[i,num_true_p[i]:]=(torch.rand(1,6-num_true_p[i])-0.5)*torch.pi\n",
    "\n",
    "            diff=diff+perm_rmse(predDoA[i, :elem].unsqueeze(dim=0),trueDoA[i, :elem].unsqueeze(dim=0))\n",
    "\n",
    "    diff= diff/len(num_true_t)  \n",
    "        \n",
    "    return diff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "T1=0 \n",
    "T2=0 \n",
    "T5=0\n",
    "T6=1\n",
    "\n",
    "T7=0\n",
    "A3=0\n",
    "A1=0\n",
    "T3=0\n",
    "\n",
    "\n",
    "train_loss_record=[]\n",
    "valid_loss_record=[]\n",
    "\n",
    "best_loss=1\n",
    "break_flag=0\n",
    "train_time =[]\n",
    "best_acc=0\n",
    "\n",
    "net=0\n",
    "model_location='./model_d/'\n",
    "\n",
    "\n",
    "# if DOAnet==1:\n",
    "#     net=trans_music(m=8).to(device)\n",
    "#     model_location='./model_d/trans_music.pt'\n",
    "\n",
    "\n",
    "if T1==1:\n",
    "    net=trans_music_two(m=8)\n",
    "    model_location='./model_d/transmusic.pt'\n",
    "  \n",
    "\n",
    "if T2==1:\n",
    "    net=separate_est_d('./model_d/transmusic.pt')\n",
    "    model_location='./model_d/transmusic_分类器.pt'\n",
    "\n",
    "\n",
    "if T5==1:\n",
    "    net=trans_music_two(m=8)\n",
    "    model_location='./model_d/transmusic_onebit.pt'\n",
    "\n",
    "\n",
    "if T6==1:\n",
    "    net=separate_est_d('./model_d/transmusic_onebit.pt')\n",
    "    model_location='./model_d/transmusic_onebit_分类器.pt'\n",
    "\n",
    "\n",
    "\n",
    "if T3==1:\n",
    "    net=trans_music_two(m=8)\n",
    "    model_location='./model_d/transmusic_onebit.pt'\n",
    "\n",
    "\n",
    "\n",
    "if T7==1:\n",
    "    net=trans_music_two(m=8)\n",
    "    model_location='./model_d/transmusic_onebit_相干.pt'\n",
    "\n",
    "\n",
    "if A3==1:\n",
    "    net=separate_est_d2('./model_d/DA_music.pt')\n",
    "    model_location='./model_d/DA_music_分类器.pt'\n",
    "\n",
    "if A1==1:\n",
    "    net=RNN_music_EVD_two(m=8)\n",
    "    model_location='./model_d/DA_music.pt'\n",
    "\n",
    "\n",
    "\n",
    "# for name, param in net.named_parameters():\n",
    "#     print(name,'-->',param.type(),'-->',param.dtype,'-->',param.shape)\n",
    "\n",
    "\n",
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print('All parameters', total_params)\n",
    "total_trainable_params = sum( p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print('All trainable parameters', total_trainable_params)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "\n",
    "epoch_num=200\n",
    "\n",
    "# net.load_state_dict(torch.load(model_location))#Load the model parameters saved above  \n",
    "\n",
    "\n",
    "train_time.append(time.time())\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_loss1=0.0\n",
    "    train_loss2=0.0\n",
    "\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_loss1 =0.0\n",
    "    val_loss2 =0.0\n",
    "    valsnr_loss = 0.0\n",
    "    valsnr_loss1 =0.0\n",
    "    valsnr_loss2 =0.0\n",
    "    vals_loss=0.0\n",
    "\n",
    "\n",
    "    net.train()  # set model to training mode\n",
    "    for X_input,X_target in tqdm(train_loader):\n",
    "\n",
    "        optimizer.zero_grad() #Gradient Zeroing\n",
    "\n",
    "        X_input = X_input.to(device)\n",
    "\n",
    "        X_target= X_target.to(device)\n",
    "\n",
    "\n",
    "        X_pre,X_d,_ = net(X_input)  # forward propagation\n",
    "\n",
    "        loss1=loss_doa(X_pre, X_target)\n",
    "        \n",
    "        loss2=loss_d(X_d,X_target)\n",
    "\n",
    "\n",
    "        batch_loss = loss1+loss2\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        train_loss += batch_loss.item()  \n",
    "        train_loss1 += loss1.item()  \n",
    "        train_loss2 += loss2.item()  \n",
    "\n",
    "\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    train_loss1 = train_loss1/len(train_loader)\n",
    "    train_loss2 = train_loss2/len(train_loader)\n",
    "\n",
    "    train_loss_record.append(train_loss)\n",
    "\n",
    "\n",
    "    train_accs0=[]\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    for x, y in valid_loader:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                pred,p_d ,_= net(x) \n",
    "                vloss1=loss_doa(pred, y)\n",
    "                vloss2=loss_d(p_d,y)\n",
    "                # vloss2=loss_d_by_one(p_d,y)\n",
    "                v_loss = vloss1+vloss2\n",
    "                val_loss+= v_loss.item()\n",
    "                val_loss1+= vloss1.item()\n",
    "                val_loss2+= vloss2.item()\n",
    "\n",
    "                prob = F.softmax(p_d,dim=1)\n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "\n",
    "                train_accs0.append(acc)\n",
    "                \n",
    "\n",
    "    val_loss=val_loss/len(valid_loader)\n",
    "    val_loss1=val_loss1/len(valid_loader)\n",
    "    val_loss2=val_loss2/len(valid_loader)\n",
    "    valid_loss_record.append(val_loss)\n",
    "    train_acc0 = sum(train_accs0) / len(train_accs0)#accuracy\n",
    "\n",
    "\n",
    "\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    train_accs = []\n",
    "    for x, y in valid_loader_snr:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                pred_snr,p_d_snr,_ = net(x) \n",
    "\n",
    "                vloss2=loss_doa(pred_snr, y)\n",
    "                \n",
    "                vsnrloss=loss_d(p_d_snr,y)\n",
    "                prob = F.softmax(p_d_snr,dim=1)\n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "\n",
    "                train_accs.append(acc)\n",
    "                valsnr_loss+= vsnrloss.item()\n",
    "                valsnr_loss1 += vloss2.item()\n",
    "\n",
    "    valsnr_loss=valsnr_loss/len(valid_loader_snr)\n",
    "\n",
    "    valsnr_loss1=valsnr_loss1/len(valid_loader_snr)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "\n",
    "\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    train_accs1 = []\n",
    "    for x, y in valid_loader_s:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                pred,p_d_s,_= net(x) \n",
    "                vloss3=loss_doa(pred, y)\n",
    "                vsloss=loss_d(p_d_s,y)\n",
    "\n",
    "\n",
    "                prob = F.softmax(p_d_s,dim=1) \n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "\n",
    "                train_accs1.append(acc)\n",
    "                vals_loss+= vsloss.item()\n",
    "                valsnr_loss2 += vloss3.item()\n",
    "\n",
    "    vals_loss=vals_loss/len(valid_loader_s)\n",
    "    valsnr_loss2=valsnr_loss2/len(valid_loader_s)\n",
    "    train_acc1 = sum(train_accs1) / len(train_accs1)#accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # s0=str(train_acc0)\n",
    "    # s1=str(train_acc)\n",
    "    # s2=str(train_acc1)\n",
    "    # md='./model_临时/transmusic_onebit_相干'+'_'+str(epoch)+'_'+s0[:6]+'_'+s1[:6]+'_'+s2[:6]+'.pt'\n",
    "    # torch.save(net.state_dict(), md)  # Save model to specified path\n",
    "\n",
    "\n",
    "\n",
    "    # if val_loss1<best_loss:#Update model with error\n",
    "    #     best_loss=val_loss1\n",
    "    #     torch.save(net.state_dict(), model_location)  # Save model to specified path\n",
    "\n",
    "    if train_acc0>best_acc:#Update model with accuracy\n",
    "        best_acc=train_acc0\n",
    "        torch.save(net.state_dict(), model_location)  # Save model to specified path\n",
    "        \n",
    "        print('save the model','epoch:',epoch)\n",
    "        break_flag = 0\n",
    "    else:\n",
    "        break_flag += 1\n",
    "# \n",
    "    if break_flag > 20:\n",
    "        break_flag=0\n",
    "        print('_____________________________________________') \n",
    "\n",
    "    print('|epoch={:2d}/{:3d}|total_time={:.2f}m|train_loss={:.4f}({:.4f}dB) | val_loss={:.4f}({:.4f}dB | best_loss={:.4f}({:.4f}dB)'.format(\n",
    "        epoch,epoch_num,(time.time()-train_time[0])/60,train_loss,20*np.log10(train_loss),val_loss,20*np.log10(val_loss),best_loss,20*np.log10(best_loss)      ))\n",
    "\n",
    "    print('|train_loss1={:.4f}({:.4f}dB)|val_loss1={:.4f}({:.4f}dB|train_loss2={:.4f}({:.4f}dB)|val_loss2={:.4f}({:.4f}dB)|Accuracy:{:.4f}'.format(\n",
    "       train_loss1,20*np.log10(train_loss1),val_loss1,20*np.log10(val_loss1),train_loss2,20*np.log10(train_loss2),val_loss2,20*np.log10(val_loss2) , train_acc0 ))\n",
    "\n",
    "    print('|10100 snapshot SNR verification set=loss error {:.4f}({:.4f}dB)   | ACC error {:.4f}({:.4f}dB) |Accuracy:{:.4f}'.format( valsnr_loss1,20*np.log10(valsnr_loss1),valsnr_loss,20*np.log10(valsnr_loss),train_acc ))\n",
    "\n",
    "    print('|d=2 Loss error {:.4f}({:.4f}dB)   | ACC error {:.4f}({:.4f}dB) |Accuracy:{:.4f}'.format( valsnr_loss2,20*np.log10(valsnr_loss2),vals_loss,20*np.log10(vals_loss),train_acc1 ))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "# best_acc=0\n",
    "epoch_num=200\n",
    "\n",
    "# net.load_state_dict(torch.load(model_location))#Load the model parameters saved above  \n",
    "\n",
    "train_time.append(time.time())\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    train_loss = 0.0\n",
    "\n",
    "    val_loss = 0.0\n",
    "   \n",
    "    valsnr_loss = 0.0\n",
    "\n",
    "    vals_loss = 0.0\n",
    "  \n",
    "    net.train()  # set model to training mode\n",
    "\n",
    "    for X_input,X_target in tqdm(train_loader):\n",
    "    # for X_input,X_target in (train_loader):\n",
    "\n",
    "        optimizer.zero_grad() #Gradient Zeroing\n",
    "\n",
    "        X_input = X_input.to(device)\n",
    "\n",
    "        X_target= X_target.to(device)\n",
    "\n",
    "        X_d = net(X_input)  # forward propagation\n",
    " \n",
    "        batch_loss=loss_d(X_d,X_target)\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(batch_loss)\n",
    "        train_loss += batch_loss.item()  # The total loss of all batches in an epoch\n",
    "       \n",
    "\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    train_loss_record.append(train_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_accs0=[]\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    for x, y in valid_loader:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                p_d= net(x)  # Forward propagation and moving X into cuda\n",
    "               \n",
    "                vloss=loss_d(p_d,y)\n",
    "                # vloss=loss_d_by_one(p_d,y)\n",
    "               \n",
    "                val_loss+= vloss.item()#The total loss of all batches in an epoch\n",
    "\n",
    "                prob = F.softmax(p_d,dim=1) # Dim=0, perform Softmax on the column; Dim=1, perform Softmax on the line\n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "                train_accs0.append(acc)\n",
    "                \n",
    "    val_loss=val_loss/len(valid_loader)\n",
    "    valid_loss_record.append(val_loss)\n",
    "    train_acc0 = sum(train_accs0) / len(train_accs0)#accuracy\n",
    "\n",
    "\n",
    "    train_accs = []\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    for x, y in valid_loader_snr:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                p_d_snr= net(x)  # Forward propagation and moving X into cuda\n",
    "                vsnrloss=loss_d(p_d_snr,y)\n",
    "                # vsnrloss=loss_d_by_one(p_d_snr,y)\n",
    "\n",
    "                prob = F.softmax(p_d_snr,dim=1) # Dim=0, perform Softmax on the column; Dim=1, perform Softmax on the line\n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "\n",
    "                train_accs.append(acc)\n",
    "                valsnr_loss+= vsnrloss.item()#The total loss of all batches in an epoch\n",
    "\n",
    "    valsnr_loss=valsnr_loss/len(valid_loader_snr)\n",
    "    train_acc = sum(train_accs) / len(train_accs)#accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_accs1 = []\n",
    "    net.eval()  # set model to evalutation mode\n",
    "    for x, y in valid_loader_s:  # iterate through the dataloader\n",
    "            with torch.no_grad():  # disable gradient calculation\n",
    "                x=x.to(device)\n",
    "                y=y.to(device)\n",
    "                p_d_s= net(x)  # Forward propagation and moving X into cuda\n",
    "                vsloss=loss_d(p_d_s,y)\n",
    "                # vsnrloss=loss_d_by_one(p_d_snr,y)\n",
    "\n",
    "                prob = F.softmax(p_d_s,dim=1) # Dim=0, perform Softmax on the column; Dim=1, perform Softmax on the line\n",
    "                num_true_t = torch.argmax(y, dim=1)\n",
    "                num_true_p=torch.argmax(prob,dim=1)\n",
    "                num_true_p=num_true_p+2\n",
    "                acc = (num_true_p == num_true_t).float().mean().item()\n",
    "\n",
    "                train_accs1.append(acc)\n",
    "                vals_loss+= vsloss.item()#The total loss of all batches in an epoch\n",
    "\n",
    "    vals_loss=vals_loss/len(valid_loader_s)\n",
    "    train_acc1 = sum(train_accs1) / len(train_accs1)#accuracy\n",
    "\n",
    "\n",
    "\n",
    "    if train_acc0>best_acc:#Update the model with validation data\n",
    "        best_acc=train_acc0\n",
    "        \n",
    "        torch.save(net.state_dict(), model_location)  # Save model to specified path\n",
    "        print('save the model','epoch:',epoch)\n",
    "        break_flag = 0\n",
    "    else:\n",
    "        break_flag += 1\n",
    "# \n",
    "    if break_flag > 20:\n",
    "        break_flag=0\n",
    "        print('_____________________________________________') \n",
    "\n",
    "    print('|epoch={:2d}/{:3d}|total_time={:.2f}m|train_loss={:.4f}({:.4f}dB) | val_loss={:.4f}({:.4f}dB | best_acc={:.4f}({:.4f}dB)'.format(\n",
    "        epoch,epoch_num,(time.time()-train_time[0])/60,train_loss,20*np.log10(train_loss),val_loss,20*np.log10(val_loss),best_acc,20*np.log10(best_loss)      ))\n",
    "\n",
    "    print('Verification set accuracy:{:.4f}'.format(train_acc0 ))\n",
    "\n",
    "    print('|100Validation set={:.4f}({:.4f}dB) |accuracy:{:.4f}'.format( valsnr_loss,20*np.log10(valsnr_loss),train_acc ))\n",
    "\n",
    "    print('|d=2Validation set={:.4f}({:.4f}dB) |accurac:{:.4f}'.format( vals_loss,20*np.log10(vals_loss),train_acc1 ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# loss reduction chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_loss_record, label='train_loss')\n",
    "plt.plot(valid_loss_record, label='valid_loss')\n",
    "plt.ylim(0., 0.5)\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('perm_rmse loss')\n",
    "plt.title('Learning curve of {}'.format(\"loss\"))\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(20*np.log10(train_loss_record), label='train_loss')\n",
    "plt.plot(20*np.log10(valid_loss_record), label='valid_loss')\n",
    "plt.ylim(-26., -3.0)\n",
    "plt.xlabel('Training epoch')\n",
    "plt.ylabel('perm_rmse (dB))')\n",
    "plt.title('Learning curve of {}'.format(\"loss\"))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e32618030883af29da10316c76c83da9a02f65dadf9a9b09d160d0d4f5840e5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
